{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Fruit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and read images into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL # image related operations\n",
    "import glob # to retriive directory information and file selection\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=glob.glob('train/*.jpg')\n",
    "test_images = glob.glob('test/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note lists below contain PIL.image objects. i.e. apple_images_train[0] is of PIL.Image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_images_train=[Image.open(i).convert('RGB') for i in train_images if 'apple' in i]\n",
    "orange_images_train=[Image.open(i).convert('RGB') for i in train_images if 'orange' in i]\n",
    "banana_images_train=[Image.open(i).convert('RGB') for i in train_images if 'banana' in i]\n",
    "mixed_images_train=[Image.open(i).convert('RGB') for i in train_images if 'mixed' in i]\n",
    "apple_images_test=[Image.open(i).convert('RGB') for i in test_images if 'apple' in i]\n",
    "orange_images_test=[Image.open(i).convert('RGB') for i in test_images if 'orange' in i]\n",
    "banana_images_test=[Image.open(i).convert('RGB') for i in test_images if 'banana' in i]\n",
    "mixed_images_test=[Image.open(i).convert('RGB') for i in test_images if 'mixed' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize and GetDatasets and two pre-processing functions. Resize will resize images with given height and weight and convert them to Numpy array. GetDatasets receives four arrays and concatenates them as a training dataset, it also creates a testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resize(list,height,weight):\n",
    "    array = np.zeros((len(list),height,weight,3))\n",
    "    for i in range(len(list)):\n",
    "        temp = list[i].resize((height,weight))\n",
    "        array[i] = np.asarray(temp)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDatasets(array0,array1,array2,array3):\n",
    "    X = np.concatenate((array0,array1,array2,array3),axis = 0)\n",
    "    y_label_encoding = np.concatenate((np.zeros(array0.shape[0]),np.ones(array1.shape[0]),2 * np.ones(array2.shape[0]),3 * np.ones(array3.shape[0])),axis = 0)\n",
    "    y_onehot = tf.keras.utils.to_categorical(y_label_encoding, 4)\n",
    "    return (X,y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = Resize(apple_images_train,100,100)\n",
    "banana = Resize(banana_images_train,100,100)\n",
    "orange = Resize(orange_images_train,100,100)\n",
    "mixed = Resize(mixed_images_train,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_test = Resize(apple_images_test,100,100)\n",
    "banana_test = Resize(orange_images_test,100,100)\n",
    "orange_test = Resize(banana_images_test,100,100)\n",
    "mixed_test = Resize(mixed_images_test,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = GetDatasets(apple,banana,orange,mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = GetDatasets(apple_test,banana,orange,mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(X_train, y_train, X_test, y_test):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), \n",
    "        activation='relu', input_shape=(100, 100, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), \n",
    "        activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(X_train, y_train, \n",
    "        batch_size=64, epochs=10, verbose=1,\n",
    "        validation_data=(X_test, y_test))\n",
    "        \n",
    "\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print(\"score =\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 9,447,972\n",
      "Trainable params: 9,447,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1788.1319 - accuracy: 0.2597 - val_loss: 462.4785 - val_accuracy: 0.3913\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 504.8994 - accuracy: 0.3401 - val_loss: 83.6945 - val_accuracy: 0.4837\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 76.6653 - accuracy: 0.5730 - val_loss: 29.9259 - val_accuracy: 0.5163\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 16.5464 - accuracy: 0.6646 - val_loss: 3.9510 - val_accuracy: 0.6793\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.7941 - accuracy: 0.6718 - val_loss: 1.8724 - val_accuracy: 0.6413\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.9362 - accuracy: 0.7149 - val_loss: 0.7150 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.4021 - accuracy: 0.7031 - val_loss: 0.4981 - val_accuracy: 0.8315\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6703 - accuracy: 0.7774 - val_loss: 0.4905 - val_accuracy: 0.8424\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5075 - accuracy: 0.8388 - val_loss: 0.4313 - val_accuracy: 0.8533\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5340 - accuracy: 0.7936 - val_loss: 0.3935 - val_accuracy: 0.8967\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.3935 - accuracy: 0.8967\n",
      "score = [0.3934800624847412, 0.89673912525177]\n"
     ]
    }
   ],
   "source": [
    "model = run_cnn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)# --->outputlayer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
